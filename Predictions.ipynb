{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import utils.resnet as resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, model):\n",
    "        super(Net, self).__init__()\n",
    "        self.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hakim\\Documents\\Python\\CK3\\Simple Regressor\\utils\\resnet.py:6: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(layer)\n"
     ]
    }
   ],
   "source": [
    "Net = Net(resnet.ResNet50(img_channel=3, num_features=101))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('./checkpoints/version_0/checkpoints/epoch=99-step=37499.ckpt')\n",
    "Net.load_state_dict(checkpoint['state_dict'])\n",
    "Net = Net.eval().to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import utils.data_processing as data_processing\n",
    "import utils.dna_parser as dna_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors = datasets.ImageFolder('./predict_images', transform=data_processing.transform)\n",
    "tensors = torch.stack([tensor[0] for tensor in tensors]).to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [transforms.functional.to_pil_image(tensor) for tensor in tensors]\n",
    "for i, image in enumerate(images):\n",
    "    image.save(f'./predictions/image#{i}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    preds = Net.model(tensors).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 3\n",
      "165 4\n",
      "61 2\n",
      "-149 5\n",
      "17 2\n",
      "161 3\n",
      "-211 4\n",
      "101 2\n",
      "95 4\n",
      "-37 3\n",
      "176 3\n",
      "64 4\n",
      "-41 9\n",
      "85 4\n",
      "-207 5\n",
      "-104 13\n",
      "50 5\n",
      "-137 6\n",
      "-71 2\n",
      "131 3\n",
      "141 3\n",
      "203 4\n",
      "164 2\n",
      "129 5\n",
      "81 2\n",
      "-116 3\n",
      "-105 4\n",
      "186 2\n",
      "163 4\n",
      "158 3\n",
      "212 3\n",
      "61 4\n",
      "-34 9\n",
      "177 4\n",
      "-86 5\n",
      "-23 13\n",
      "67 5\n",
      "-18 6\n",
      "-66 2\n",
      "98 3\n"
     ]
    }
   ],
   "source": [
    "for i, dna in enumerate(preds):\n",
    "    dna_parser.array_to_dna(dna.clip(min=-255, max=255), f\"./predictions/prediction#{i}.txt\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1596998366379c828b844cdf503cd102a74185cb9cc58a80a39dab5431602623"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('Deeplearning': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
