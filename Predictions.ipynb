{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import utils.resnet as resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, model):\n",
    "        super(Net, self).__init__()\n",
    "        self.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hakim\\Documents\\Python\\CK3\\Simple Regressor\\utils\\resnet.py:6: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(layer)\n"
     ]
    }
   ],
   "source": [
    "Net = Net(resnet.ResNet50(img_channel=3, num_features=101))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('./checkpoints/version_0/checkpoints/epoch=99-step=37499.ckpt')\n",
    "Net.load_state_dict(checkpoint['state_dict'])\n",
    "Net = Net.eval().to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import utils.data_processing as data_processing\n",
    "import utils.dna_parser as dna_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors = datasets.ImageFolder('./predict_images', transform=data_processing.transform)\n",
    "tensors = torch.stack([tensor[0] for tensor in tensors]).to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [transforms.functional.to_pil_image(tensor) for tensor in tensors]\n",
    "for i, image in enumerate(images):\n",
    "    image.save(f'./predictions/image#{i}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    preds = Net.model(tensors).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-126 3\n",
      "134 4\n",
      "-210 2\n",
      "255 5\n",
      "-245 2\n",
      "-144 3\n",
      "24 4\n",
      "198 2\n",
      "9 4\n",
      "45 3\n",
      "222 3\n",
      "63 4\n",
      "-249 9\n",
      "89 4\n",
      "-162 5\n",
      "-177 13\n",
      "-70 5\n",
      "91 6\n",
      "-50 2\n",
      "108 3\n",
      "-107 3\n",
      "-104 4\n",
      "-55 2\n",
      "132 5\n",
      "-145 2\n",
      "146 3\n",
      "-50 4\n",
      "-136 2\n",
      "-34 4\n",
      "-106 3\n",
      "146 3\n",
      "77 4\n",
      "-161 9\n",
      "125 4\n",
      "-41 5\n",
      "-134 13\n",
      "95 5\n",
      "-75 6\n",
      "-65 2\n",
      "160 3\n",
      "-221 3\n",
      "-89 4\n",
      "1 2\n",
      "100 5\n",
      "-54 2\n",
      "219 3\n",
      "-16 4\n",
      "143 2\n",
      "88 4\n",
      "-239 3\n",
      "-18 3\n",
      "80 4\n",
      "-214 9\n",
      "16 4\n",
      "-226 5\n",
      "-227 13\n",
      "-11 5\n",
      "-147 6\n",
      "-65 2\n",
      "46 3\n",
      "236 3\n",
      "131 4\n",
      "169 2\n",
      "229 5\n",
      "-10 2\n",
      "-30 3\n",
      "148 4\n",
      "205 2\n",
      "17 4\n",
      "25 3\n",
      "251 3\n",
      "68 4\n",
      "74 9\n",
      "167 4\n",
      "-153 5\n",
      "-148 13\n",
      "24 5\n",
      "-220 6\n",
      "-78 2\n",
      "63 3\n",
      "-15 3\n",
      "118 4\n",
      "41 2\n",
      "234 5\n",
      "-223 2\n",
      "161 3\n",
      "213 4\n",
      "47 2\n",
      "-44 4\n",
      "-209 3\n",
      "69 3\n",
      "59 4\n",
      "-93 9\n",
      "-23 4\n",
      "-146 5\n",
      "-228 13\n",
      "138 5\n",
      "-15 6\n",
      "-39 2\n",
      "20 3\n",
      "215 3\n",
      "-19 4\n",
      "153 2\n",
      "217 5\n",
      "-74 2\n",
      "-47 3\n",
      "27 4\n",
      "-139 2\n",
      "-140 4\n",
      "46 3\n",
      "214 3\n",
      "62 4\n",
      "-91 9\n",
      "25 4\n",
      "154 5\n",
      "-158 13\n",
      "204 5\n",
      "-179 6\n",
      "-61 2\n",
      "118 3\n",
      "237 3\n",
      "190 4\n",
      "199 2\n",
      "-69 5\n",
      "-48 2\n",
      "-173 3\n",
      "-21 4\n",
      "-70 2\n",
      "-91 4\n",
      "-3 3\n",
      "177 3\n",
      "55 4\n",
      "-218 9\n",
      "115 4\n",
      "-76 5\n",
      "-194 13\n",
      "101 5\n",
      "-130 6\n",
      "-73 2\n",
      "92 3\n",
      "2 3\n",
      "-34 4\n",
      "-184 2\n",
      "57 5\n",
      "-255 2\n",
      "-235 3\n",
      "120 4\n",
      "-213 2\n",
      "121 4\n",
      "48 3\n",
      "242 3\n",
      "60 4\n",
      "54 9\n",
      "104 4\n",
      "-115 5\n",
      "9 13\n",
      "48 5\n",
      "-195 6\n",
      "-63 2\n",
      "70 3\n"
     ]
    }
   ],
   "source": [
    "for i, dna in enumerate(preds):\n",
    "    dna_parser.array_to_dna(dna.clip(min=-255, max=255), f\"./predictions/prediction#{i}.txt\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1596998366379c828b844cdf503cd102a74185cb9cc58a80a39dab5431602623"
  },
  "kernelspec": {
   "display_name": "Deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
