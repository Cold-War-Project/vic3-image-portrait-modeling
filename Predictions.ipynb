{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import utils.resnet as resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, model):\n",
    "        super(Net, self).__init__()\n",
    "        self.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hakim\\Documents\\Python\\CK3\\Simple Regressor\\utils\\resnet.py:6: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(layer)\n"
     ]
    }
   ],
   "source": [
    "Net = Net(resnet.ResNet50(img_channel=3, num_features=101))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('./checkpoints/torngasuk_dataset2-resnet50-ReLU_linear/checkpoints/epoch=99-step=37499.ckpt')\n",
    "Net.load_state_dict(checkpoint['state_dict'])\n",
    "Net = Net.eval().to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import utils.data_processing as data_processing\n",
    "import utils.dna_parser as dna_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors = datasets.ImageFolder('./predict_images', transform=data_processing.transform)\n",
    "tensors = torch.stack([tensor[0] for tensor in tensors]).to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [transforms.functional.to_pil_image(tensor) for tensor in tensors]\n",
    "for i, image in enumerate(images):\n",
    "    image.save(f'./predictions/image#{i}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    preds = Net.model(tensors).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-216 3\n",
      "241 4\n",
      "108 2\n",
      "255 5\n",
      "255 2\n",
      "255 3\n",
      "255 4\n",
      "-172 2\n",
      "63 4\n",
      "141 3\n",
      "-198 3\n",
      "20 4\n",
      "-231 9\n",
      "255 4\n",
      "121 5\n",
      "-255 13\n",
      "-218 5\n",
      "-207 6\n",
      "115 2\n",
      "56 3\n",
      "194 3\n",
      "214 4\n",
      "128 2\n",
      "129 5\n",
      "255 2\n",
      "255 3\n",
      "117 4\n",
      "-12 2\n",
      "-147 4\n",
      "66 3\n",
      "-46 3\n",
      "-9 4\n",
      "-6 9\n",
      "238 4\n",
      "-163 5\n",
      "-194 13\n",
      "-224 5\n",
      "-198 6\n",
      "42 2\n",
      "3 3\n",
      "93 3\n",
      "-69 4\n",
      "196 2\n",
      "-82 5\n",
      "255 2\n",
      "255 3\n",
      "246 4\n",
      "-161 2\n",
      "124 4\n",
      "243 3\n",
      "-180 3\n",
      "50 4\n",
      "-183 9\n",
      "140 4\n",
      "157 5\n",
      "-248 13\n",
      "-209 5\n",
      "-51 6\n",
      "89 2\n",
      "65 3\n",
      "43 3\n",
      "-44 4\n",
      "-56 2\n",
      "178 5\n",
      "149 2\n",
      "2 3\n",
      "-158 4\n",
      "11 2\n",
      "87 4\n",
      "-128 3\n",
      "-72 3\n",
      "75 4\n",
      "-130 9\n",
      "155 4\n",
      "-100 5\n",
      "-71 13\n",
      "-37 5\n",
      "-122 6\n",
      "-59 2\n",
      "25 3\n",
      "-54 3\n",
      "255 4\n",
      "-99 2\n",
      "203 5\n",
      "255 2\n",
      "255 3\n",
      "218 4\n",
      "109 2\n",
      "175 4\n",
      "150 3\n",
      "-247 3\n",
      "73 4\n",
      "-254 9\n",
      "255 4\n",
      "147 5\n",
      "-206 13\n",
      "39 5\n",
      "174 6\n",
      "6 2\n",
      "121 3\n",
      "29 3\n",
      "116 4\n",
      "-13 2\n",
      "143 5\n",
      "163 2\n",
      "203 3\n",
      "-45 4\n",
      "64 2\n",
      "117 4\n",
      "-47 3\n",
      "-4 3\n",
      "38 4\n",
      "-55 9\n",
      "192 4\n",
      "-147 5\n",
      "52 13\n",
      "-72 5\n",
      "-66 6\n",
      "-57 2\n",
      "108 3\n",
      "-98 3\n",
      "-23 4\n",
      "78 2\n",
      "-46 5\n",
      "168 2\n",
      "195 3\n",
      "50 4\n",
      "213 2\n",
      "181 4\n",
      "-192 3\n",
      "28 3\n",
      "45 4\n",
      "13 9\n",
      "189 4\n",
      "120 5\n",
      "-111 13\n",
      "30 5\n",
      "-169 6\n",
      "-25 2\n",
      "14 3\n",
      "41 3\n",
      "33 4\n",
      "149 2\n",
      "254 5\n",
      "255 2\n",
      "255 3\n",
      "111 4\n",
      "239 2\n",
      "61 4\n",
      "-116 3\n",
      "-114 3\n",
      "25 4\n",
      "-110 9\n",
      "246 4\n",
      "217 5\n",
      "-251 13\n",
      "-103 5\n",
      "23 6\n",
      "-19 2\n",
      "-50 3\n"
     ]
    }
   ],
   "source": [
    "for i, dna in enumerate(preds):\n",
    "    dna_parser.array_to_dna(dna.clip(min=-255, max=255), f\"./predictions/prediction#{i}.txt\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1596998366379c828b844cdf503cd102a74185cb9cc58a80a39dab5431602623"
  },
  "kernelspec": {
   "display_name": "Deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
